{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addWord(word):\n",
    "    with open('vocab.txt', 'a') as voc:\n",
    "        for i in words:\n",
    "            voc.write(str(i[0]) + ' --- ' + str(i[1]) + '  +' '\\n')\n",
    "            \n",
    "def addWord(l1, l2, sign):\n",
    "    with open('vocab.txt', 'a') as voc:\n",
    "        voc.write(str(l1) + ' --- ' + str(l2) + '  ( ' + sign + ' )\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emptyVoc():\n",
    "    with open('vocab.txt', 'w') as voc:\n",
    "        a = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeWordLang(word):\n",
    "    lang1 = list()\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            i[1] = i[1][:-1]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        for i in lang1:\n",
    "            if i[0] == word:\n",
    "                lang1.remove(i)\n",
    "    with open('vocab.txt', 'w') as voc:\n",
    "        for i in lang1:\n",
    "            voc.write(str(i[0]) + ' --- ' + str(i[1]) + '\\n')\n",
    "            \n",
    "def removeWordTrans(word):\n",
    "    lang2 = list()\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            i[1] = i[1][:-1]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        for i in lang2:\n",
    "            if i[1] == word:\n",
    "                lang2.remove(i)\n",
    "    with open('vocab.txt', 'w') as voc:\n",
    "        for i in lang2:\n",
    "            voc.write(str(i[0]) + ' --- ' + str(i[1]) + '\\n')\n",
    "            \n",
    "def removeWord(word):\n",
    "    lang1 = list()\n",
    "    lang2 = list()\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            i[1] = i[1][:-1]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        for i in lang1:\n",
    "            if i[0] == word:\n",
    "                lang1.remove(i)\n",
    "        for i in lang2:\n",
    "            if i[1] == word:\n",
    "                lang2.remove(i)\n",
    "    with open('vocab.txt', 'w') as voc:\n",
    "        if len(lang1) > len(lang2):\n",
    "            for i in lang2:\n",
    "                voc.write(str(i[0]) + ' --- ' + str(i[1]) + '\\n')\n",
    "        else:\n",
    "            for i in lang1:\n",
    "                voc.write(str(i[0]) + ' --- ' + str(i[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            i[1] = i[1][:-1]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        transl_is_found = False\n",
    "        for i in lang1:\n",
    "            if i[0] == word:\n",
    "                transl_is_found = True\n",
    "                print i[1]\n",
    "            if i[1] == word:\n",
    "                transl_is_found = True\n",
    "                print i[0]\n",
    "        if transl_is_found == False:\n",
    "            print 'Sys: *No such word in the vocab*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSecond(elem):\n",
    "    return elem[1].lower()\n",
    "def getFirst(elem):\n",
    "    return elem[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printVocab():\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            #print i\n",
    "            i.append(i[1][-4])\n",
    "            #print i[2]\n",
    "            i[1] = i[1][:-6]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        for i in lang1:\n",
    "            print i[0], ' - ', i[1], '  (',i[2],')'\n",
    "        #print \n",
    "        #for i in lang2:\n",
    "        #    print i[0], ' - ', i[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parserNewWords():\n",
    "    s_beg = '<a href=\"javascript:void(0)\" data-role=\"translate\" data-added=\"true\">'\n",
    "    s_end = '</a>'\n",
    "    with open('raw.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        word = str()\n",
    "        for i in data_list:\n",
    "            if i.find(s_beg) != -1:\n",
    "                beg = i.find(s_beg) + 69\n",
    "                word = i[beg : -5]\n",
    "                addWord(word, '***', '-')\n",
    "                \n",
    "def parserKnownWords():\n",
    "    s_beg = '<a href=\"javascript:void(0)\" class=\"btn-translate-autohide\" data-role=\"translate\" data-old=\"true\">'\n",
    "    s_end = '</a>'\n",
    "    with open('raw.txt', 'r') as voc:\n",
    "        data_list = voc.readlines()\n",
    "        word = str()\n",
    "        for i in data_list:\n",
    "            if i.find(s_beg) != -1:\n",
    "                beg = i.find(s_beg) + 98\n",
    "                word = i[beg : -5]\n",
    "                addWord(word, '***', '+')\n",
    "    with open('vocab.txt', 'r') as voc:\n",
    "        tmp = list()\n",
    "        for i in data_list:\n",
    "            tmp.append(i.split(' --- ')) \n",
    "        for i in tmp:\n",
    "            i.append(i[1][-4])\n",
    "            i[1] = i[1][:-6]\n",
    "        lang1 = list(tmp)\n",
    "        lang2 = list(tmp)\n",
    "        lang1.sort(key = getFirst)\n",
    "        lang2.sort(key = getSecond)\n",
    "        bucket = list()\n",
    "        for i in range (1, len(lang1)):\n",
    "            if (lang1[i - 1][0] == lang1[i][0] and (lang1[i - 1][2] != '+' or lang1[i][2] != '+')):\n",
    "                lang1[i - 1][2] = '-'\n",
    "                #lang1.remove(i)\n",
    "                bucket.append(i)\n",
    "        bucket.reverse()\n",
    "        #for i in bucket:\n",
    "        #    lang1.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "addWord() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-447-9418c62a0a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0maddWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: addWord() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "d = list()\n",
    "d.append(['1', '3'])\n",
    "addWord(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "addWord('1', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "addWord('asdf', 'qwer', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "removeWordLang('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "removeWordTrans('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "removeWord('qwer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accompany  -  ***     ( - )\n",
      "accomplishment  -  ***     ( - )\n",
      "accounting  -  ***     ( - )\n",
      "acquired  -  ***     ( - )\n",
      "agitated  -  ***     ( - )\n",
      "altogether  -  ***     ( - )\n",
      "Andover  -  ***     ( - )\n",
      "antitrust  -  ***     ( - )\n",
      "applicable  -  ***     ( - )\n",
      "assign  -  ***     ( - )\n",
      "assignment  -  ***     ( - )\n",
      "assumptions  -  ***     ( - )\n",
      "atrocity  -  ***     ( - )\n",
      "auctions  -  ***     ( - )\n",
      "audit  -  ***     ( - )\n",
      "awkward  -  ***     ( - )\n",
      "backfires  -  ***     ( - )\n",
      "biped  -  ***     ( - )\n",
      "breadcrumbs  -  ***     ( - )\n",
      "calculus  -  ***     ( - )\n",
      "chin  -  ***     ( - )\n",
      "chip  -  ***     ( - )\n",
      "ciphers  -  ***     ( - )\n",
      "clearance  -  ***     ( - )\n",
      "cloaking  -  ***     ( - )\n",
      "commitment  -  ***     ( - )\n",
      "competitive  -  ***     ( - )\n",
      "comportment  -  ***     ( - )\n",
      "compromised  -  ***     ( - )\n",
      "conjectures  -  ***     ( - )\n",
      "constitutional  -  ***     ( - )\n",
      "contrary  -  ***     ( - )\n",
      "Conviction  -  ***     ( - )\n",
      "dam  -  ***     ( - )\n",
      "daunting  -  ***     ( - )\n",
      "dazzle  -  ***     ( - )\n",
      "decays  -  ***     ( - )\n",
      "decipher  -  ***     ( - )\n",
      "deeds  -  ***     ( - )\n",
      "dispersal  -  ***     ( - )\n",
      "dissolved  -  ***     ( - )\n",
      "distinguish  -  ***     ( - )\n",
      "drivel  -  ***     ( - )\n",
      "drool  -  ***     ( - )\n",
      "eager  -  ***     ( - )\n",
      "embedding  -  ***     ( - )\n",
      "equilibrium  -  ***     ( - )\n",
      "faction  -  ***     ( - )\n",
      "flattered  -  ***     ( - )\n",
      "flawed  -  ***     ( - )\n",
      "fleeing  -  ***     ( - )\n",
      "fluid  -  ***     ( - )\n",
      "fondly  -  ***     ( - )\n",
      "governing  -  ***     ( - )\n",
      "haunt  -  ***     ( - )\n",
      "helpings  -  ***     ( - )\n",
      "hubris  -  ***     ( - )\n",
      "imbedded  -  ***     ( - )\n",
      "imprisonment  -  ***     ( - )\n",
      "incinerated  -  ***     ( - )\n",
      "incur  -  ***     ( - )\n",
      "indulge  -  ***     ( - )\n",
      "inimitable  -  ***     ( - )\n",
      "injected  -  ***     ( - )\n",
      "insult  -  ***     ( - )\n",
      "intends  -  ***     ( - )\n",
      "interaction  -  ***     ( - )\n",
      "intercepting  -  ***     ( - )\n",
      "intercourse  -  ***     ( - )\n",
      "isolate  -  ***     ( - )\n",
      "latitudes  -  ***     ( - )\n",
      "lesser  -  ***     ( - )\n",
      "longitudes  -  ***     ( - )\n",
      "magnitude  -  ***     ( - )\n",
      "manifold  -  ***     ( - )\n",
      "miscalculation  -  ***     ( - )\n",
      "mortals  -  ***     ( - )\n",
      "Mortified  -  ***     ( - )\n",
      "mugging  -  ***     ( - )\n",
      "narrowed  -  ***     ( - )\n",
      "niece  -  ***     ( - )\n",
      "obligation  -  ***     ( - )\n",
      "ops  -  ***     ( - )\n",
      "overtime  -  ***     ( - )\n",
      "packages  -  ***     ( - )\n",
      "palate  -  ***     ( - )\n",
      "persuaded  -  ***     ( - )\n",
      "pinpoint  -  ***     ( - )\n",
      "preliminary  -  ***     ( - )\n",
      "presumptuous  -  ***     ( - )\n",
      "prevalence  -  ***     ( - )\n",
      "prodigal  -  ***     ( - )\n",
      "redefine  -  ***     ( - )\n",
      "refractive  -  ***     ( - )\n",
      "reinstate  -  ***     ( - )\n",
      "repatriating  -  ***     ( - )\n",
      "restraints  -  ***     ( - )\n",
      "revealed  -  ***     ( - )\n",
      "reverie  -  ***     ( - )\n",
      "sapien  -  ***     ( - )\n",
      "savior  -  ***     ( - )\n",
      "scholars  -  ***     ( - )\n",
      "scintillating  -  ***     ( - )\n",
      "screw  -  ***     ( - )\n",
      "seaboard  -  ***     ( - )\n",
      "seized  -  ***     ( - )\n",
      "serum  -  ***     ( - )\n",
      "sidelines  -  ***     ( - )\n",
      "singularities  -  ***     ( - )\n",
      "slap  -  ***     ( - )\n",
      "slate  -  ***     ( - )\n",
      "sporadically  -  ***     ( - )\n",
      "squashed  -  ***     ( - )\n",
      "squawk  -  ***     ( - )\n",
      "stratagems  -  ***     ( - )\n",
      "stun  -  ***     ( - )\n",
      "supremely  -  ***     ( - )\n",
      "tire  -  ***     ( - )\n",
      "tremendous  -  ***     ( - )\n",
      "triggers  -  ***     ( - )\n",
      "trivia  -  ***     ( - )\n",
      "ultimately  -  ***     ( - )\n",
      "vanguard  -  ***     ( - )\n",
      "verifiable  -  ***     ( - )\n",
      "wander  -  ***     ( - )\n",
      "whim  -  ***     ( - )\n",
      "wit  -  ***     ( - )\n",
      "zap  -  ***     ( - )\n"
     ]
    }
   ],
   "source": [
    "printVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwer\n"
     ]
    }
   ],
   "source": [
    "translate('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sys: *No such word in the vocab*\n"
     ]
    }
   ],
   "source": [
    "translate('qwer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "parserNewWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-664-e360307e0091>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparserKnownWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-659-f1b8acf5be82>\u001b[0m in \u001b[0;36mparserKnownWords\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' --- '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mlang1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "parserKnownWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyVoc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
